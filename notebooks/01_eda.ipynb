{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Dataset - Exploratory Data Analysis\n",
    "\n",
    "Dans ce notebook, nous allons explorer le dataset California Housing pour comprendre :\n",
    "- La distribution des variables\n",
    "- Les corrélations entre features\n",
    "- La présence d'outliers\n",
    "- La skewness des distributions\n",
    "\n",
    "Cette analyse nous aidera à définir notre stratégie de preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Chargement du dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame.copy()\n",
    "\n",
    "print(\"Dimensions du dataset:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nDescription des features:\")\n",
    "for name, desc in zip(data.feature_names, data.feature_names_original):\n",
    "    print(f\"- {name}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse Statistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Statistiques descriptives\n",
    "display(df.describe())\n",
    "\n",
    "# Vérification des valeurs manquantes\n",
    "missing = df.isnull().sum()\n",
    "if missing.any():\n",
    "    print(\"\\nValeurs manquantes:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"\\nAucune valeur manquante !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse des Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Distribution des variables\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    sns.histplot(data=df, x=col, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribution de {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse de la skewness\n",
    "skewness = df.skew().sort_values(ascending=False)\n",
    "print(\"\\nSkewness des variables:\")\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse des Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Boxplots pour détecter les outliers\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    sns.boxplot(data=df, y=col, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Boxplot de {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcul du pourcentage d'outliers par variable\n",
    "def detect_outliers_iqr(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return ((column < (Q1 - 1.5 * IQR)) | (column > (Q3 + 1.5 * IQR))).sum() / len(column) * 100\n",
    "\n",
    "outliers_pct = pd.Series({col: detect_outliers_iqr(df[col]) for col in df.columns})\n",
    "print(\"\\nPourcentage d'outliers par variable:\")\n",
    "print(outliers_pct.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse des Corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Matrice de corrélation\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matrice de Corrélation')\n",
    "plt.show()\n",
    "\n",
    "# Corrélations avec la variable cible\n",
    "target_corr = df.corr()['MedHouseVal'].sort_values(ascending=False)\n",
    "print(\"\\nCorrélations avec MedHouseVal:\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisations Avancées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Pairplot des variables les plus corrélées avec la cible\n",
    "top_features = target_corr[1:4].index  # Top 3 features\n",
    "sns.pairplot(df, vars=list(top_features) + ['MedHouseVal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "De cette analyse exploratoire, nous pouvons conclure :\n",
    "\n",
    "1. Distribution des données :\n",
    "   - Certaines variables présentent une forte asymétrie\n",
    "   - Présence d'outliers significatifs\n",
    "\n",
    "2. Corrélations :\n",
    "   - Les features les plus corrélées avec le prix\n",
    "   - Potentielles multicolinéarités\n",
    "\n",
    "3. Stratégie de preprocessing suggérée :\n",
    "   - Traitement des outliers\n",
    "   - Transformation des variables skewed\n",
    "   - Standardisation des features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
