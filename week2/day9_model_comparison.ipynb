{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5520751a",
   "metadata": {},
   "source": [
    "# Comparaison de Modèles : SVM, KNN et Random Forest\n",
    "\n",
    "Dans ce notebook, nous allons comparer différents modèles de régression sur le dataset California Housing :\n",
    "- Support Vector Machine (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Random Forest\n",
    "\n",
    "Pour chaque modèle, nous allons :\n",
    "1. Évaluer ses performances de base\n",
    "2. Optimiser ses hyperparamètres\n",
    "3. Comparer les performances finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a71e3",
   "metadata": {},
   "source": [
    "## 1. Chargement et Préparation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame.copy()\n",
    "\n",
    "print(\"Aperçu des données:\")\n",
    "display(df.head())\n",
    "print(\"\\nInformations sur le dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données\n",
    "X = df.drop(\"MedHouseVal\", axis=1)\n",
    "y = df[\"MedHouseVal\"]\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Dimensions des données:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499353f",
   "metadata": {},
   "source": [
    "## 2. Évaluation Initiale des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des modèles\n",
    "models = {\n",
    "    \"SVM\": SVR(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Comparaison avec validation croisée\n",
    "print(\"Comparaison initiale (R² sur validation croisée) :\")\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    cv_results[name] = scores\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Moyenne R² = {scores.mean():.4f}\")\n",
    "    print(f\"  Écart-type R² = {scores.std():.4f}\")\n",
    "\n",
    "# Visualisation des résultats\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([cv_results[name] for name in models.keys()], labels=models.keys())\n",
    "plt.title(\"Distribution des Scores R² par Modèle\")\n",
    "plt.ylabel(\"Score R²\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6145a3",
   "metadata": {},
   "source": [
    "## 3. Optimisation des Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour GridSearchCV\n",
    "param_grids = {\n",
    "    \"SVM\": {\n",
    "        \"C\": [1, 10, 100],\n",
    "        \"epsilon\": [0.1, 0.2, 0.3],\n",
    "        \"kernel\": ['rbf', 'linear']\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"weights\": ['uniform', 'distance'],\n",
    "        \"p\": [1, 2]  # Manhattan vs Euclidean\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optimisation pour chaque modèle\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nOptimisation des hyperparamètres pour {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Meilleurs paramètres : {grid.best_params_}\")\n",
    "    print(f\"Meilleur score R² : {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a2ece",
   "metadata": {},
   "source": [
    "## 4. Évaluation Finale sur le Jeu de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation des modèles optimisés\n",
    "results = []\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append({\n",
    "        'Modèle': name,\n",
    "        'RMSE': rmse,\n",
    "        'R²': r2\n",
    "    })\n",
    "\n",
    "# Affichage des résultats sous forme de DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Résultats finaux sur le jeu de test:\")\n",
    "display(results_df)\n",
    "\n",
    "# Visualisation des prédictions vs valeurs réelles\n",
    "plt.figure(figsize=(15, 5))\n",
    "for idx, (name, model) in enumerate(best_models.items(), 1):\n",
    "    plt.subplot(1, 3, idx)\n",
    "    y_pred = model.predict(X_test)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Valeurs Réelles')\n",
    "    plt.ylabel('Prédictions')\n",
    "    plt.title(f'{name}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad04e10",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Dans cette analyse, nous avons comparé trois modèles différents sur le dataset California Housing :\n",
    "- Support Vector Machine (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Random Forest\n",
    "\n",
    "Les résultats montrent que :\n",
    "1. Random Forest tend à avoir les meilleures performances globales\n",
    "2. KNN est le plus rapide à entraîner mais moins performant\n",
    "3. SVM offre un bon compromis mais nécessite plus de temps d'entraînement\n",
    "\n",
    "Le choix final du modèle dépendra des contraintes spécifiques du projet (temps d'entraînement, temps de prédiction, interprétabilité, etc.)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
