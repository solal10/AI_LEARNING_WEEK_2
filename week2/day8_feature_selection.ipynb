{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf20fbc",
   "metadata": {},
   "source": [
    "# Feature Engineering, Encodage et Sélection de Features\n",
    "\n",
    "Dans ce notebook, nous allons explorer différentes techniques de sélection et d'analyse de features, notamment :\n",
    "- L'importance des features via Random Forest\n",
    "- La sélection de features avec SelectKBest\n",
    "- L'analyse en composantes principales (PCA)\n",
    "- Les corrélations entre features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aea041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cad3e",
   "metadata": {},
   "source": [
    "## 1. Chargement et Préparation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf781a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame.copy()\n",
    "\n",
    "print(\"Aperçu des données:\")\n",
    "display(df.head())\n",
    "print(\"\\nInformations sur le dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.drop(\"MedHouseVal\", axis=1))\n",
    "y = df[\"MedHouseVal\"]\n",
    "\n",
    "print(\"Shape des données après préparation:\")\n",
    "print(\"X:\", X_scaled.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa84475",
   "metadata": {},
   "source": [
    "## 2. Importance des Features via Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8021a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du Random Forest pour l'importance des features\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_scaled, y)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Création d'une série pandas pour faciliter la visualisation\n",
    "features = df.drop(\"MedHouseVal\", axis=1).columns\n",
    "feat_importances = pd.Series(importances, index=features).sort_values(ascending=False)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=feat_importances.values, y=feat_importances.index)\n",
    "plt.title(\"Importance des Features (Random Forest)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nImportance des features (en pourcentage):\")\n",
    "for feat, imp in feat_importances.items():\n",
    "    print(f\"{feat}: {imp*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce58da6",
   "metadata": {},
   "source": [
    "## 3. Sélection de Features avec SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d41182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de SelectKBest avec f_regression\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "X_kbest = selector.fit_transform(X_scaled, y)\n",
    "selected_features = features[selector.get_support()]\n",
    "\n",
    "print(\"Top 5 features sélectionnées avec SelectKBest:\")\n",
    "scores = pd.Series(selector.scores_, index=features).sort_values(ascending=False)\n",
    "for feat, score in scores.head().items():\n",
    "    print(f\"{feat}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ee32a",
   "metadata": {},
   "source": [
    "## 4. Analyse en Composantes Principales (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Visualisation de la variance expliquée\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         np.cumsum(pca.explained_variance_ratio_), 'bo-')\n",
    "plt.xlabel('Nombre de composantes')\n",
    "plt.ylabel('Variance expliquée cumulée')\n",
    "plt.title('Variance expliquée cumulée vs. Nombre de composantes')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVariance expliquée par composante:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {var*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7603bd",
   "metadata": {},
   "source": [
    "## 5. Analyse des Corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Matrice de Corrélation des Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identification des paires de features fortement corrélées\n",
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "strong_corr = [(col1, col2, corr_matrix.loc[col1, col2]) \n",
    "               for col1 in corr_matrix.columns \n",
    "               for col2 in corr_matrix.columns \n",
    "               if corr_matrix.loc[col1, col2] > 0.5 and col1 < col2]\n",
    "\n",
    "print(\"\\nPaires de features fortement corrélées (>0.5):\")\n",
    "for col1, col2, corr in strong_corr:\n",
    "    print(f\"{col1} - {col2}: {corr:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
