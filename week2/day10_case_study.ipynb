{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a8ab58",
   "metadata": {},
   "source": [
    "# Étude de Cas Complète : Analyse de Données et Modélisation\n",
    "\n",
    "Dans ce notebook, nous allons réaliser une étude de cas complète sur un dataset de diamants.\n",
    "Nous suivrons les étapes typiques d'un projet de Machine Learning :\n",
    "\n",
    "1. Exploration et nettoyage des données\n",
    "2. Feature engineering et préparation\n",
    "3. Modélisation et évaluation\n",
    "4. Optimisation des modèles\n",
    "5. Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfc0eb",
   "metadata": {},
   "source": [
    "## 1. Chargement et Exploration des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "try:\n",
    "    df = sns.load_dataset(\"diamonds\")\n",
    "    dataset_name = \"Diamonds\"\n",
    "except:\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame.copy()\n",
    "    dataset_name = \"California Housing\"\n",
    "\n",
    "print(f\"Dataset utilisé : {dataset_name}\")\n",
    "print(\"\\nAperçu des données :\")\n",
    "display(df.head())\n",
    "print(\"\\nInformations sur le dataset :\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362779dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse statistique descriptive\n",
    "print(\"Statistiques descriptives :\")\n",
    "display(df.describe())\n",
    "\n",
    "# Visualisation de la distribution des variables numériques\n",
    "plt.figure(figsize=(15, 10))\n",
    "df.select_dtypes(include=[np.number]).hist(bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ed150",
   "metadata": {},
   "source": [
    "## 2. Nettoyage et Préparation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9001d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "print(\"Valeurs manquantes avant nettoyage :\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "df = df.dropna()\n",
    "print(\"\\nValeurs manquantes après nettoyage :\")\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des features\n",
    "target = df.columns[-1]\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Encodage des variables catégorielles si présentes\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"Features après encodage :\")\n",
    "print(f\"Nombre de features : {X.shape[1]}\")\n",
    "print(\"Liste des features :\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0c15e",
   "metadata": {},
   "source": [
    "## 3. Split Train/Test et Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dimensions des données :\")\n",
    "print(f\"X_train : {X_train_scaled.shape}\")\n",
    "print(f\"X_test : {X_test_scaled.shape}\")\n",
    "print(f\"y_train : {y_train.shape}\")\n",
    "print(f\"y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504fbfa",
   "metadata": {},
   "source": [
    "## 4. Modélisation Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des modèles\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Évaluation initiale\n",
    "results = []\n",
    "print(\"Évaluation initiale des modèles :\")\n",
    "for name, model in models.items():\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Entraînement sur l'ensemble complet\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Modèle': name,\n",
    "        'R² CV Moyen': cv_scores.mean(),\n",
    "        'R² CV Std': cv_scores.std(),\n",
    "        'RMSE Test': rmse,\n",
    "        'R² Test': r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb728b",
   "metadata": {},
   "source": [
    "## 5. Optimisation des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des grilles de paramètres\n",
    "param_grids = {\n",
    "    \"Ridge\": {\n",
    "        \"alpha\": [0.1, 1.0, 10.0],\n",
    "        \"solver\": ['auto', 'svd', 'cholesky']\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optimisation et évaluation\n",
    "best_models = {}\n",
    "final_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nOptimisation de {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='r2', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "    y_pred = grid.best_estimator_.predict(X_test_scaled)\n",
    "    \n",
    "    final_results.append({\n",
    "        'Modèle': name,\n",
    "        'Meilleurs Paramètres': grid.best_params_,\n",
    "        'R² CV': grid.best_score_,\n",
    "        'RMSE Test': mean_squared_error(y_test, y_pred, squared=False),\n",
    "        'R² Test': r2_score(y_test, y_pred)\n",
    "    })\n",
    "    \n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "display(final_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde470a3",
   "metadata": {},
   "source": [
    "## 6. Visualisation des Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des prédictions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for idx, (name, model) in enumerate(best_models.items(), 1):\n",
    "    plt.subplot(1, 2, idx)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Valeurs Réelles')\n",
    "    plt.ylabel('Prédictions')\n",
    "    plt.title(f'{name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10a23b",
   "metadata": {},
   "source": [
    "## 7. Conclusion et Perspectives\n",
    "\n",
    "Dans cette étude de cas, nous avons :\n",
    "1. Exploré et nettoyé les données\n",
    "2. Préparé les features avec encodage et standardisation\n",
    "3. Évalué deux modèles différents (Ridge et Random Forest)\n",
    "4. Optimisé les hyperparamètres\n",
    "5. Comparé les performances finales\n",
    "\n",
    "Pour le projet final, il est recommandé de :\n",
    "- Choisir un dataset personnel sur Kaggle ou OpenML\n",
    "- Définir clairement l'objectif (classification ou régression)\n",
    "- Organiser le code comme un vrai projet avec :\n",
    "  - `src/` pour le code source\n",
    "  - `notebooks/` pour l'exploration\n",
    "  - `scripts/` pour les utilitaires\n",
    "  - Un README détaillé"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
